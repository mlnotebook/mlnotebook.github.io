<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Machine Learning Notebook</title>
    <link>/post/index.xml</link>
    <description>Recent content in Posts on Machine Learning Notebook</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Mar 2017 19:27:27 +0000</lastBuildDate>
    <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Surface Distance Function</title>
      <link>/post/surface-distance-function/</link>
      <pubDate>Wed, 01 Mar 2017 19:27:27 +0000</pubDate>
      
      <guid>/post/surface-distance-function/</guid>
      <description>

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;Recently, I have been doing a &lt;strong&gt;lot&lt;/strong&gt; of segmentation evaluation - seeing how good a segmentation done by a machine compares with one that&amp;rsquo;s done manual, a &amp;lsquo;ground truth&amp;rsquo; (GT). Traditionally, such verification is done by comparing the overlap between the two e.g. Dice Simlarity Coefficient (DSC) [1]. There are a few different calculations that can be done (there&amp;rsquo;ll be a longer post on just that) and &amp;lsquo;surface distance&amp;rsquo; calculations are one of them.&lt;/p&gt;

&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;

&lt;p&gt;For this calculation, we need to be able to find the outline of the segmentation and compare it to the outline of the GT. We can then take measurements of how far each segmentation pixel is from its corresponding pixel in the GT outline.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at the maths. Surface distance metrics estimate the error between the outer surfaces $S$ and $S^{\prime}$ of the segmentations $X$ and $X^{\prime}$. The distance between a point $p$ on surface $S$ and the surface $S^{\prime}$ is given by the minimum of the Euclidean norm:&lt;/p&gt;

&lt;div&gt;$$ d(p, S^{\prime}) = \min_{p^{\prime} \in S^{\prime}} \left|\left| p - p^{\prime} \right|\right|_{2} $$&lt;/div&gt;

&lt;p&gt;Doing this for all pixels in the surface gives the total surface distance between $S$ and $S^{\prime}$: $d(S, S^{\prime})$:&lt;/p&gt;

&lt;p&gt;Now I&amp;rsquo;ve seen MATLAB code that can do this, though often its not entirely accurate. Plus I wanted to do this calculation on-the-fly as part of my program which was written in Python. So I came up with this function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;import numpy as np
from scipy.ndimage import morphology

def surfd(input1, input2, sampling=1, connectivity=1):
    
    input_1 = np.atleast_1d(input1.astype(np.bool))
    input_2 = np.atleast_1d(input2.astype(np.bool))
    

    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)

    S = input_1 - morphology.binary_erosion(input_1, conn)
    Sprime = input_2 - morphology.binary_erosion(input_2, conn)

    
    dta = morphology.distance_transform_edt(~S,sampling)
    dtb = morphology.distance_transform_edt(~Sprime,sampling)
    
    sds = np.concatenate([np.ravel(dta[Sprime!=0]), np.ravel(dtb[S!=0])])
       
    
    return sds
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Lets go through it bit-by-bit. The function &lt;em&gt;surfd&lt;/em&gt; is defined to take in four variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;input1&lt;/em&gt; - the segmentation that has been created. It can be a multi-class segmentation, but this function will make the image binary. We&amp;rsquo;ll talk about how to use this function on individual classes later.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;input2&lt;/em&gt; - the GT segmentation against which we wish to compare &lt;em&gt;input1&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;sampling&lt;/em&gt; - the pixel resolution or pixel size. This is entered as an &lt;em&gt;n&lt;/em&gt;-vector where &lt;em&gt;n&lt;/em&gt; is equal to the number of dimensions in the segmentation i.e. 2D or 3D. The default value is 1 which means pixels (or rather voxels) are 1 x 1 x 1 mm in size.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;connectivity&lt;/em&gt; - creates either a 2D (3 x 3) or 3D (3 x 3 x 3) matrix defining the neighbourhood around which the function looks for neighbouring pixels. Typically, this is defined as a six-neighbour kernel which is the default behaviour of this function.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First we&amp;rsquo;ll be making use of simple numpy operations, but we&amp;rsquo;ll also need the &lt;em&gt;morphology&lt;/em&gt; module from &lt;em&gt;scipy&lt;/em&gt;&amp;rsquo;s &lt;em&gt;dnimage&lt;/em&gt; package. These are imported first. More information on this module can be found &lt;a href=&#34;https://docs.scipy.org/doc/scipy-0.18.1/reference/ndimage.html&#34; title=&#34;Scipy _ndimage_ package&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;import numpy as np
from scipy.ndimage import morphology
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The two inputs are checked for their size and made binary. Any value greater than zero is made 1 (true).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;    input_1 = np.atleast_1d(input1.astype(np.bool))
    input_2 = np.atleast_1d(input2.astype(np.bool))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use the the &lt;em&gt;morphology.generate_binary_structure&lt;/em&gt; function, along with the number of dimensions of the segmentation, to create the kernel that will be used to detect the edges of the segmentations. This could be done just by hard-coding the kernel itself: &lt;code&gt;[[0 0 0],[0 1 0],[0 0 0]; [0 1 0], [1 1 1], [0 1 0]; [0 0 0], [0 1 0], [0 0 0]]&lt;/code&gt;. This kernel &amp;lsquo;&lt;em&gt;conn&lt;/em&gt;&amp;rsquo; is supplied to the &lt;em&gt;morphology.binary_erosion&lt;/em&gt; function which strips the outermost pixel from the edge of the segmentation. Subtracting this result from the segmentation itself leaves only the single-pixel-wide surface.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)

    S = input_1 - morphology.binary_erosion(input_1, conn)
    Sprime = input_2 - morphology.binary_erosion(input_2, conn)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we again use the &lt;em&gt;morphology&lt;/em&gt; module. This time we give the &lt;em&gt;distance_transform_edt&lt;/em&gt; function our pixel-size (&lt;em&gt;samping&lt;/em&gt;) and also the inverted surface-image. The inversion is used such that the surface itself is given the value of zero i.e. any pixel at this location, will have zero surface-distance. The transform increases the value/error/penalty of the remaining pixels with increasing distance away from the surface.&lt;/p&gt;

&lt;p&gt;Each pixel of the opposite segmentation-surface is then laid upon this &amp;lsquo;map&amp;rsquo; of penalties and both results are concatenated into a vector which is as long as the number of pixels in the surface of each segmentation. This vector of &lt;em&gt;surface distances&lt;/em&gt; is returned. Note that this is technically the &lt;em&gt;symmetric&lt;/em&gt; surface distance as we are not assuming that just doing this for &lt;em&gt;one&lt;/em&gt; of the surfaces is enough. It may be that the distance between a pixel in A and in B is not the same as between the pixel in B and in A. i.e. $d(S, S^{\prime}) \neq d(S^{\prime}, S)$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;    dta = morphology.distance_transform_edt(~input1_border,sampling)
    dtb = morphology.distance_transform_edt(~Sprime,sampling)
    
    sds = np.concatenate([np.ravel(dta[Sprime!=0]), np.ravel(dtb[S!=0])])
        
    return sds
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;how-is-it-used&#34;&gt;How is it used?&lt;/h2&gt;

&lt;p&gt;The function example below takes two segmentations (which both have multiple classes). The sampling vector is a typical pixel-size from an MRI scan and the 1 indicated I&amp;rsquo;d like a 6 neighbour (cross-shaped) kernel for finding the edges.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;    surface_distance = surfd(test_seg, GT_seg, [1.25, 1.25, 10],1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By specifcing the value of the voxel-label I&amp;rsquo;m interested in (assuming we&amp;rsquo;re talking about classes which are contiguous and not spread out), we can find the surface accuracy of that class.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;    surface_distance = surfd(test_seg(test_seg==1), \
                   GT_seg(GT_seg==1), [1.25, 1.25, 10],1)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;what-do-the-results-mean&#34;&gt;What do the results mean?&lt;/h2&gt;

&lt;p&gt;The returned surface distances can be used to calculate:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Mean Surface Distance (MSD)&lt;/em&gt; - the mean of the vector is taken. This tell us how much, on average, the surface varies between the segmentation and the GT (in mm).&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;$$     \text{MSD} = \frac{1}{n_{S} + n_{S^{\prime}}} \left( \sum_{p = 1}^{n_{S}} d(p, S^{\prime}) + \sum_{p^{\prime}=1}^{n_{S^{\prime}}} d(p^{\prime}, S) \right) $$ &lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Residual Mean Square Distance (RMS)&lt;/em&gt; - as it says, the mean is taken from each of the points in the vector, these residuals are squared (to remove negative signs), summated, weighted by the mean and then the square-root is taken. Measured in mm.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;$$ \text{RMS} = \sqrt{\frac{1}{n_{S} + n_{S^{\prime}}} \left( \sum_{p = 1}^{n_{S}} d(p, S^{\prime})^{2} + \sum_{p^{\prime}=1}^{n_{S^{\prime}}} d(p^{\prime}, S)^{2} \right) }\ $$&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Hausdorff Distance (HD)&lt;/em&gt; - the maximum of the vector. The largest difference between the surface distances. Also measured in mm. We calculate the &lt;em&gt;symmetric Hausdorff distance&lt;/em&gt; as:&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div&gt;$$\text{HD} = \max \left[ d(S, S^{\prime}) , d(S^{\prime}, S) \right]$$&lt;/div&gt;

&lt;p&gt;Or in Python:
&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;    msd = surface_distance.mean()
    rms = np.sqrt((surface_distance**2).mean())
    hd  = surface_distance.max()
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;[1]     Dice, L. R. (1945). Measures of the Amount of Ecologic Association Between Species. Ecology, 26(3), 297–302. &lt;a href=&#34;https://doi.org/10.2307/1932409&#34;&gt;https://doi.org/10.2307/1932409&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MLNotebook First Post</title>
      <link>/post/my-first-post/</link>
      <pubDate>Wed, 01 Mar 2017 10:38:47 +0000</pubDate>
      
      <guid>/post/my-first-post/</guid>
      <description>&lt;p&gt;This is the first post on the Machine Learning Notebook (MLN)!&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m a n00b when it comes to Github Pages and relatively new to working with Github at all! It took me a while to decide what platform to use for creating this humble resource. I was initially looking at writing everything in iPython notebooks, but it was confusing to figure out how to keep the scripts live rather than coverting them to static sites.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve read several blogs, but &lt;a href=&#34;http://bruceeckel.github.io/2014/11/19/using-github-pages/&#34; title=&#34;Using Github Pages&#34;&gt;this one&lt;/a&gt; seemed to be written to my liking and was pretty much a document of trail and error, but perhaps more imporantly, &lt;strong&gt;solutions&lt;/strong&gt;. I&amp;rsquo;m actually writing this first post after reading &lt;a href=&#34;https://www.smashingmagazine.com/2014/08/build-blog-jekyll-github-pages/&#34; title=&#34;Build a Blog with Jekyll and Github Pages&#34;&gt;this&lt;/a&gt; where I&amp;rsquo;ve settled on using Jekyll. Though I must say that I was initially pushed away from this idea after seeing that Jekyll was written for Ruby (in which I have no experience). But here it goes - hopefully it&amp;rsquo;ll be straight-forward.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Edit&lt;/strong&gt;&lt;/em&gt;: Scratch that - after playing around with &lt;a href=&#34;https://gohugo.io/&#34; title=&#34;Hugo Homepage&#34;&gt;Hugo&lt;/a&gt; and reading the &amp;lsquo;start from scratch&amp;rsquo; post &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-install-and-use-hugo-a-static-site-generator-on-ubuntu-14-04#adjusting-the-initial-configuration-for-your-site&#34; title=&#34;Quickstart Hugo&#34;&gt;here&lt;/a&gt; I think I&amp;rsquo;m a hugo-convert!&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m (still) going to have to play about with writing in markdown just to get used to the command structure. Luckily, I found a good cheatsheet over &lt;a href=&#34;https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet&#34; title=&#34;Markdown Cheatsheet&#34;&gt;here&lt;/a&gt; and another &lt;a href=&#34;https://sourceforge.net/p/hugo-generator/wiki/markdown_syntax/&#34; title=&#34;Sourceforge Markdown&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Eventually, I want this site to build up into small sampling of what I&amp;rsquo;ve been learning to do whilst learning Python and applying it to Machine Learning problems. It may at times become quite specialised with my research in medical imaging, but the general processes (I hope) should benefit at least one other person in the world.&lt;/p&gt;

&lt;p&gt;Here goes!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Edit&lt;/strong&gt;&lt;/em&gt;: Just to test out the code-block highlighting&amp;hellip;
&lt;pre&gt;&lt;code class=&#34;python&#34;
&gt;def hello_world():
    print &amp;ldquo;Hello there!&amp;rdquo;
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>